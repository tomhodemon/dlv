{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
    "!unzip annotations_trainval2017.zip\n",
    "!wget http://images.cocodataset.org/zips/val2017.zip\n",
    "!unzip val2017.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else\n",
    "                      \"mps\" if torch.backends.mps.is_available() else\n",
    "                      \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_folder = \"./val2017/\"\n",
    "ann_file = \"./annotations/instances_val2017.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.23s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import coco_loader\n",
    "import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "coco_val_dataset = coco_loader.get_coco(\"./\", \"val\", transforms.preprocessing())\n",
    "\n",
    "coco_val_dataloader = DataLoader(coco_val_dataset, batch_size=1, collate_fn=coco_loader.collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load SSD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.SSD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1q/rxjynltx6gd_27l52x3hgms40000gn/T/ipykernel_91039/402868697.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(pretrained_weights_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained weights loaded successfully.\n",
      "Using device: mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SSD(\n",
       "  (backbone): SSDFeatureExtractorVGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): ReLU(inplace=True)\n",
       "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "    )\n",
       "    (extra): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): Sequential(\n",
       "          (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "          (1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (4): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3-4): 2 x Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (anchor_generator): DefaultBoxGenerator(aspect_ratios=[[2], [2, 3], [2, 3], [2, 3], [2], [2]], clip=True, scales=[0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05], steps=[8, 16, 32, 64, 100, 300])\n",
       "  (head): SSDHead(\n",
       "    (classification_head): SSDClassificationHead(\n",
       "      (module_list): ModuleList(\n",
       "        (0): Conv2d(512, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(1024, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(512, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4-5): 2 x Conv2d(256, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (regression_head): SSDRegressionHead(\n",
       "      (module_list): ModuleList(\n",
       "        (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4-5): 2 x Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.48235, 0.45882, 0.40784], std=[0.00392156862745098, 0.00392156862745098, 0.00392156862745098])\n",
       "      Resize(min_size=(300,), max_size=300, mode='bilinear')\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_weights_path = \"./detection_weights.pth\"\n",
    "\n",
    "try:\n",
    "    state_dict = torch.load(pretrained_weights_path)\n",
    "    model.load_state_dict(state_dict)\n",
    "    print(\"Pretrained weights loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Pretrained weights file not found. Using random initialization.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading pretrained weights: {e}\")\n",
    "\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'boxes': tensor([[ 66.7423,   2.4333, 254.4296, 179.7254],\n",
      "        [ 29.0987,   8.3231, 121.0340, 145.6343],\n",
      "        [ 68.4127,   1.9898, 224.2879,  88.9117],\n",
      "        [101.4719,  38.6244, 215.8796, 271.5144],\n",
      "        [ 77.0356,   7.6081, 148.2795, 157.0774],\n",
      "        [ 10.0958,   1.8035, 154.1074,  92.0238],\n",
      "        [  1.9470,   2.5276, 297.9933, 291.7701],\n",
      "        [100.7676,  11.1990, 187.6620, 146.3891],\n",
      "        [  0.9750,  24.8637,  93.3101, 285.1259],\n",
      "        [  4.7343,   5.3064,  85.5404, 164.9816],\n",
      "        [ 45.1872,  32.2139, 176.8828, 176.8904],\n",
      "        [170.5552,   3.9978, 245.7159, 157.2764],\n",
      "        [124.9561,  19.8686, 232.2591, 131.7829],\n",
      "        [ 27.1778,  24.7875, 148.5425, 284.9632],\n",
      "        [ 84.4237,  19.1376, 157.4299,  93.5421],\n",
      "        [140.0864,  28.6276, 210.2670, 191.9264],\n",
      "        [140.7885,   0.7260, 289.1700,  91.1463],\n",
      "        [ 44.1579,  60.1773, 113.5528, 222.5150],\n",
      "        [163.0043,  33.3721, 292.5776, 279.4531],\n",
      "        [113.3206,   4.2678, 192.4581,  77.4008],\n",
      "        [163.4855,  19.6743, 237.6956,  93.0676],\n",
      "        [  2.2733,   3.0192,  79.8192,  81.5896],\n",
      "        [  8.7277,   0.0000, 291.2407, 296.0541],\n",
      "        [ 49.7052,  19.3465, 124.7202,  94.7045],\n",
      "        [115.7675,  34.6892, 189.2335, 108.6117],\n",
      "        [194.1109,  18.2735, 272.3917,  93.9126],\n",
      "        [205.3447,  20.6203, 284.3492, 197.4179],\n",
      "        [  1.3111,  84.6990,  99.6095, 203.0763],\n",
      "        [  3.8956,   2.5812, 292.7471, 293.6594],\n",
      "        [ 31.1161,  43.3530, 203.3615, 113.7862],\n",
      "        [ 37.7562,   8.8971,  74.3277,  72.0104],\n",
      "        [223.0583,   1.7317, 299.5414,  81.0631],\n",
      "        [ 20.9803,   7.9784,  58.4586,  72.8774],\n",
      "        [117.5647,  84.0439, 186.7184, 157.1641],\n",
      "        [217.8317,  20.4574, 245.7427,  95.4375],\n",
      "        [201.9200,  20.4908, 230.0714,  95.4641],\n",
      "        [  3.8956,   2.5812, 292.7471, 293.6594],\n",
      "        [ 68.3487,  35.1654, 140.6540, 108.9866],\n",
      "        [  1.9470,   2.5276, 297.9933, 291.7701],\n",
      "        [ 54.4739,   9.8379,  89.9449,  71.6227],\n",
      "        [ 84.7182,  69.5956, 209.0985, 153.2700],\n",
      "        [173.8461,  60.3650, 240.6777, 224.3642],\n",
      "        [ 86.4264,  84.1019, 155.4346, 156.8151],\n",
      "        [ 17.6832,  32.6880,  92.9058, 109.8041],\n",
      "        [229.7929,   8.9693, 266.4149,  72.0916],\n",
      "        [ 70.6614,  26.7882, 105.1382,  87.5953],\n",
      "        [118.3829,  26.6650, 154.0036,  86.6987],\n",
      "        [185.8381,  20.7656, 214.5976,  94.2532],\n",
      "        [206.1623,  90.3992, 282.7948, 263.4857],\n",
      "        [ 80.3151,  59.1254, 146.2296, 220.7239],\n",
      "        [ 86.7379,  27.0466, 121.6612,  87.2444],\n",
      "        [166.2812,  26.7045, 202.3070,  86.6584],\n",
      "        [102.3465,  26.7678, 137.8033,  86.8753],\n",
      "        [134.4021,  26.6430, 169.9478,  86.6922],\n",
      "        [237.6195,  48.0910, 299.7116, 242.3912],\n",
      "        [131.9064,  51.6754, 204.1478, 124.5460],\n",
      "        [  6.1212, 156.3015,  82.5098, 300.0000],\n",
      "        [105.7094,  85.5721, 134.1542, 158.9123],\n",
      "        [100.8391,  52.2086, 172.8218, 124.6970],\n",
      "        [121.7568,  85.5315, 150.2664, 158.6956],\n",
      "        [ 13.5382,  67.3463, 142.2067, 154.3599],\n",
      "        [153.5764,  20.5002, 182.5072,  93.9844],\n",
      "        [102.2986,  98.9653, 171.2718, 173.3727],\n",
      "        [  0.0000,  90.8170, 215.2098, 228.3340],\n",
      "        [ 89.9092,  85.5117, 118.0158, 158.8757],\n",
      "        [218.1952,  85.3611, 245.2650, 158.4676],\n",
      "        [ 74.3241,  85.3959, 101.8916, 158.7706],\n",
      "        [143.9766,   0.0000, 208.6942,  91.9589],\n",
      "        [ 58.5044,  85.4652,  86.4746, 158.4476],\n",
      "        [ 42.7862, 125.8762, 113.9716, 286.7766],\n",
      "        [246.7434,   8.0933, 283.2835,  72.1700],\n",
      "        [ 58.3242,  36.7024,  86.3806, 110.2438],\n",
      "        [ 35.2032,  99.1616, 108.3133, 172.6937],\n",
      "        [148.8607,  85.5814, 218.5735, 156.3390],\n",
      "        [137.5503,  85.6405, 166.2267, 158.8310],\n",
      "        [ 38.4190,  42.0195,  73.8079, 103.4073],\n",
      "        [121.6927,  52.5716, 150.1938, 126.0632],\n",
      "        [208.0450,  33.3865, 256.2135,  80.0826],\n",
      "        [105.7105,  52.9249, 133.8958, 126.5410],\n",
      "        [172.9236,  26.1890, 298.4249, 121.8661],\n",
      "        [  4.4379,   7.4678,  41.8816,  74.6273],\n",
      "        [133.6578,  99.6468, 202.4497, 173.5034],\n",
      "        [137.6639,  52.3116, 166.2281, 126.1332],\n",
      "        [ 41.7925, 100.4513,  69.9714, 174.5671],\n",
      "        [  1.9470,   2.5276, 297.9933, 291.7701],\n",
      "        [  1.9470,   2.5276, 297.9933, 291.7701],\n",
      "        [ 61.3505, 132.4410, 257.4996, 300.0000],\n",
      "        [ 41.0529, 116.0145, 277.5477, 300.0000]], device='mps:0',\n",
      "       grad_fn=<StackBackward0>), 'scores': tensor([0.0520, 0.0473, 0.0473, 0.0414, 0.0412, 0.0411, 0.0406, 0.0406, 0.0404,\n",
      "        0.0392, 0.0378, 0.0372, 0.0371, 0.0361, 0.0333, 0.0329, 0.0326, 0.0320,\n",
      "        0.0317, 0.0312, 0.0312, 0.0309, 0.0290, 0.0288, 0.0286, 0.0285, 0.0284,\n",
      "        0.0278, 0.0272, 0.0267, 0.0264, 0.0262, 0.0260, 0.0260, 0.0255, 0.0254,\n",
      "        0.0253, 0.0252, 0.0252, 0.0249, 0.0249, 0.0244, 0.0244, 0.0244, 0.0240,\n",
      "        0.0240, 0.0236, 0.0236, 0.0234, 0.0233, 0.0232, 0.0232, 0.0231, 0.0231,\n",
      "        0.0231, 0.0230, 0.0230, 0.0229, 0.0229, 0.0226, 0.0225, 0.0225, 0.0222,\n",
      "        0.0222, 0.0221, 0.0220, 0.0219, 0.0219, 0.0215, 0.0214, 0.0214, 0.0213,\n",
      "        0.0212, 0.0211, 0.0211, 0.0209, 0.0209, 0.0208, 0.0208, 0.0208, 0.0208,\n",
      "        0.0206, 0.0206, 0.0205, 0.0181, 0.0138, 0.0117, 0.0106],\n",
      "       device='mps:0', grad_fn=<IndexBackward0>), 'labels': tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1, 28,  1,  1,  1,  1,  1,  5,  1,  1,  1,  1,  1,  1,  1,\n",
      "        61,  1, 65,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 38,  9,  5, 35],\n",
      "       device='mps:0')}]\n"
     ]
    }
   ],
   "source": [
    "dummy_input = [torch.rand(3, 300, 300).to(device)]\n",
    "\n",
    "output = model(dummy_input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coco_eval\n",
    "\n",
    "coco_evaluator = coco_eval.CocoEvaluator(coco_val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([64, 72, 72, 62, 62, 62, 62,  1,  1, 78, 82, 84, 84, 85, 86, 86, 62, 86,\n",
      "        86, 67], device='mps:0')\n",
      "tensor([23], device='mps:0')\n",
      "tensor([65, 64, 84, 84, 84, 84, 84, 62, 64, 84, 84, 84, 84, 84, 84, 84, 84],\n",
      "       device='mps:0')\n",
      "tensor([13,  8,  3, 13], device='mps:0')\n",
      "tensor([88, 88, 88, 65], device='mps:0')\n",
      "tensor([ 1, 35], device='mps:0')\n",
      "tensor([82, 79], device='mps:0')\n",
      "tensor([37,  1,  1, 40], device='mps:0')\n",
      "tensor([ 1,  1,  1,  1,  1, 43,  1,  1,  1], device='mps:0')\n",
      "tensor([43, 31, 31,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 27, 27,  1,  1],\n",
      "       device='mps:0')\n",
      "tensor([16,  9,  9,  1,  1,  1,  1, 77, 27, 31,  9], device='mps:0')\n",
      "tensor([77, 85,  1,  1], device='mps:0')\n",
      "tensor([7, 1, 1, 1, 1, 1, 1], device='mps:0')\n",
      "tensor([54, 51], device='mps:0')\n",
      "tensor([ 1, 42], device='mps:0')\n",
      "tensor([73, 74, 76, 72, 74], device='mps:0')\n",
      "tensor([3, 3, 3, 3, 8, 3, 3, 3], device='mps:0')\n",
      "tensor([6, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 6], device='mps:0')\n",
      "tensor([17, 76], device='mps:0')\n",
      "tensor([5, 5, 1, 1, 1, 1, 1], device='mps:0')\n",
      "tensor([24, 24], device='mps:0')\n",
      "tensor([65, 62, 62, 67], device='mps:0')\n",
      "tensor([ 6,  1,  1, 32, 32,  1, 10, 10], device='mps:0')\n",
      "tensor([51, 53], device='mps:0')\n",
      "tensor([ 1,  1, 39,  1,  1], device='mps:0')\n",
      "tensor([49, 49, 61, 46, 46, 46, 46, 46, 46, 46, 46, 46, 47, 47, 67, 49],\n",
      "       device='mps:0')\n",
      "tensor([ 1, 42], device='mps:0')\n",
      "tensor([32, 32, 32, 32,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 32, 32,\n",
      "        32, 32, 32,  1], device='mps:0')\n",
      "tensor([46, 47, 47, 49, 50, 50, 67,  1,  1], device='mps:0')\n",
      "tensor([ 1,  1,  1,  1, 35], device='mps:0')\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.336\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.500\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.376\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.301\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.087\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.800\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "IoU metric: bbox\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "\n",
    "writer = SummaryWriter(log_dir=\"runs/coco_eval\")\n",
    "\n",
    "for _, (images, targets) in zip(range(30), coco_val_dataloader):\n",
    "#for images, targets in coco_val_dataloader:\n",
    "\n",
    "    images = [img.to(device) for img in images]\n",
    "\n",
    "    targets = [\n",
    "        {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in t.items()}\n",
    "        for t in targets\n",
    "    ]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "\n",
    "    predictions = {\n",
    "        target[\"image_id\"]: {\n",
    "            \"boxes\": output[\"boxes\"].to(device),\n",
    "            \"scores\": output[\"scores\"].to(device),\n",
    "            \"labels\": output[\"labels\"].to(device),\n",
    "        }\n",
    "        for target, output in zip(targets, outputs)\n",
    "    }\n",
    "\n",
    "    coco_evaluator.update(predictions)\n",
    "\n",
    "coco_evaluator.accumulate()\n",
    "coco_evaluator.summarize()\n",
    "\n",
    "for iou_type, coco_eval in coco_evaluator.coco_eval.items():\n",
    "    print(f\"IoU metric: {iou_type}\")\n",
    "\n",
    "    mAP = coco_eval.stats[0]\n",
    "\n",
    "    writer.add_scalar(f'{iou_type}/mAP', mAP)\n",
    "    precision = coco_eval.stats[1]\n",
    "    recall = coco_eval.stats[2]\n",
    "    \n",
    "    writer.add_scalar(f'{iou_type}/Precision', precision)\n",
    "    writer.add_scalar(f'{iou_type}/Recall', recall)\n",
    "\n",
    "writer.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
